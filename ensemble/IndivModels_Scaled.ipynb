{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCjAUn-Ogwtv"
      },
      "outputs": [],
      "source": [
        "# load libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn import linear_model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import xgboost as xgb\n",
        "from scipy import stats\n",
        "\n",
        "import warnings\n",
        "\n",
        "# suppress all warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# set seed\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# specify file paths\n",
        "train_df = \"train_subset.csv\"\n",
        "train_targets = \"train_targets.csv\"\n",
        "\n",
        "# read in files\n",
        "X = pd.read_csv(train_df)\n",
        "y = pd.read_csv(train_targets)['AAC']   # keep only AAC column\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "FJUsIM2FlVxT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a97287b-2188-4d2a-b8d6-caeef6e6246c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(742, 457)\n",
            "(742,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un-penalized Linear Regression Model"
      ],
      "metadata": {
        "id": "_4C6fTxosZRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe to store results\n",
        "model_df = pd.DataFrame(columns=['Model', 'Fold', 'Spearman', 'Pearson'])\n",
        "\n",
        "# initialize the outer folds (5 folds, 80% train, 20% test)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# initialize variables to store best model correlation and features\n",
        "best_corr = 0\n",
        "best_fold = 0\n",
        "best_feat = None\n",
        "\n",
        "# loop through each of the outer five folds\n",
        "fold = 1\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "\n",
        "  # split train and test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # initialize linear regression model\n",
        "  reg = linear_model.LinearRegression()\n",
        "\n",
        "  # fit model\n",
        "  reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # get predicted values for test data\n",
        "  y_pred = reg.predict(X_test_scaled)\n",
        "\n",
        "  # compute correlations\n",
        "  s_cor = stats.spearmanr(y_pred, y_test)\n",
        "  p_cor = stats.pearsonr(y_pred, y_test)\n",
        "\n",
        "  # save model correlation and features (if better than previous)\n",
        "  if s_cor[0] > best_corr:\n",
        "          best_corr = s_cor[0]\n",
        "          best_fold = fold\n",
        "          best_feat = reg.coef_\n",
        "\n",
        "  # save results to dataframe\n",
        "  new_row = pd.DataFrame({'Model': ['Linear'], 'Fold': [fold], 'Spearman': [s_cor[0]], 'Pearson': [p_cor[0]]})\n",
        "  model_df = pd.concat([model_df, new_row],ignore_index = True)\n",
        "\n",
        "  # print results from fold\n",
        "  print(\"Fold\", fold, \"Spearman correlation:\", s_cor[0])\n",
        "\n",
        "  fold += 1\n",
        "\n",
        "# print best results\n",
        "print(\"\\nBest correlation:\", best_corr, \"from Fold\", best_fold)\n",
        "\n",
        "# create feature importance dataframe\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Peak': X_train.columns,\n",
        "    'Weight': best_feat\n",
        "}).sort_values(by='Weight', ascending=False)\n",
        "\n",
        "# save feature importance dataframe\n",
        "filename = f\"lm_features.csv\"\n",
        "feature_importance.to_csv(filename, index=False)\n",
        "\n",
        "model_df.to_csv('lm.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oFBHcoXrWb2",
        "outputId": "3efaf3b3-e157-4083-d740-ecb3a59adcf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman correlation: 0.16514979607280156\n",
            "Fold 2 Spearman correlation: 0.37989986437942075\n",
            "Fold 3 Spearman correlation: 0.26720022804599586\n",
            "Fold 4 Spearman correlation: 0.33431679405580367\n",
            "Fold 5 Spearman correlation: 0.24743599948493225\n",
            "\n",
            "Best correlation: 0.37989986437942075 from Fold 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LASSO Model"
      ],
      "metadata": {
        "id": "BD6UlJN-td7_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe to store results\n",
        "model_df = pd.DataFrame(columns=['Model', 'Fold', 'Spearman', 'Pearson', 'alpha', 'max_iter'])\n",
        "\n",
        "# initialize the outer folds (5 folds, 80% train, 20% test)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# initialize variables to store best model correlation and features\n",
        "best_corr = 0\n",
        "best_fold = 0\n",
        "best_feat = None\n",
        "\n",
        "# loop through each of the outer five folds\n",
        "fold = 1\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "\n",
        "  # split train and test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # initialize LASSO model\n",
        "  lasso = linear_model.Lasso()\n",
        "\n",
        "  # specify parameters for optimization\n",
        "  parameters = {\n",
        "      'alpha': [0.001, 0.01, 0.1, 1, 10, 100],\n",
        "      'max_iter': [500, 1000, 5000, 7500]\n",
        "    }\n",
        "\n",
        "  # identify optimal parameters\n",
        "  reg = GridSearchCV(\n",
        "      estimator = lasso,\n",
        "      param_grid = parameters,\n",
        "      #verbose=2\n",
        "    )\n",
        "\n",
        "  # fit model\n",
        "  reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # get best model parameters\n",
        "  reg_best = reg.best_estimator_\n",
        "\n",
        "  alpha = reg.best_params_['alpha']\n",
        "  max_iter = reg.best_params_['max_iter']\n",
        "\n",
        "  # get predicted values for test data\n",
        "  y_pred = reg_best.predict(X_test_scaled)\n",
        "\n",
        "  # compute correlations\n",
        "  s_cor = stats.spearmanr(y_pred, y_test)\n",
        "  p_cor = stats.pearsonr(y_pred, y_test)\n",
        "\n",
        "  # save model correlation and features (if better than previous)\n",
        "  if s_cor[0] > best_corr:\n",
        "          best_corr = s_cor[0]\n",
        "          best_fold = fold\n",
        "          best_feat = reg_best.coef_\n",
        "\n",
        "  # save results to dataframe\n",
        "  new_row = pd.DataFrame({'Model': ['LASSO'], 'Fold': [fold], 'Spearman': [s_cor[0]], 'Pearson': [p_cor[0]],\n",
        "                          'alpha': [alpha], 'max_iter': [max_iter]})\n",
        "  model_df = pd.concat([model_df, new_row],ignore_index = True)\n",
        "\n",
        "  # print results from fold\n",
        "  print(\"Fold\", fold, \"Spearman correlation:\", s_cor[0])\n",
        "\n",
        "  fold += 1\n",
        "\n",
        "# print results\n",
        "print(\"\\nBest correlation:\", best_corr, \"from Fold\", best_fold)\n",
        "\n",
        "# create feature importance dataframe\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Peak': X_train.columns,\n",
        "    'Weight': best_feat\n",
        "}).sort_values(by='Weight', ascending=False)\n",
        "\n",
        "# save feature importance dataframe\n",
        "filename = f\"lasso_features.csv\"\n",
        "feature_importance.to_csv(filename, index=False)\n",
        "\n",
        "model_df.to_csv('lasso.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63aiMYVMtdG4",
        "outputId": "5d8ca0eb-7f53-4656-928d-ad5dfe2b60cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman correlation: 0.3414387279510999\n",
            "Fold 2 Spearman correlation: 0.4237500932147501\n",
            "Fold 3 Spearman correlation: 0.47257754935214474\n",
            "Fold 4 Spearman correlation: 0.5135256696421251\n",
            "Fold 5 Spearman correlation: 0.3592691788873918\n",
            "\n",
            "Best correlation: 0.5135256696421251 from Fold 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ridge Model"
      ],
      "metadata": {
        "id": "9XWQ7WaFtlGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe to store results\n",
        "model_df = pd.DataFrame(columns=['Model', 'Fold', 'Spearman', 'Pearson', 'alpha', 'max_iter'])\n",
        "\n",
        "# initialize the outer folds (5 folds, 80% train, 20% test)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# initialize variables to store best model correlation and features\n",
        "best_corr = 0\n",
        "best_fold = 0\n",
        "best_feat = None\n",
        "\n",
        "# loop through each of the outer five folds\n",
        "fold = 1\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "\n",
        "  # split train and test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # initialize LASSO model\n",
        "  ridge = linear_model.Ridge()\n",
        "\n",
        "  # specify parameters for optimization\n",
        "  parameters = {\n",
        "      'alpha': [0.1, 1, 10, 100],\n",
        "      'max_iter': [500, 1000, 5000, 7500]\n",
        "    }\n",
        "\n",
        "  # identify optimal parameters\n",
        "  reg = GridSearchCV(\n",
        "      estimator = ridge,\n",
        "      param_grid = parameters,\n",
        "      #verbose=2\n",
        "    )\n",
        "\n",
        "  # fit model\n",
        "  reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # get best model parameters\n",
        "  reg_best = reg.best_estimator_\n",
        "\n",
        "  alpha = reg.best_params_['alpha']\n",
        "  max_iter = reg.best_params_['max_iter']\n",
        "\n",
        "  # get predicted values for test data\n",
        "  y_pred = reg_best.predict(X_test_scaled)\n",
        "\n",
        "  # compute correlations\n",
        "  s_cor = stats.spearmanr(y_pred, y_test)\n",
        "  p_cor = stats.pearsonr(y_pred, y_test)\n",
        "\n",
        "  # save model correlation and features (if better than previous)\n",
        "  if s_cor[0] > best_corr:\n",
        "          best_corr = s_cor[0]\n",
        "          best_fold = fold\n",
        "          best_feat = reg_best.coef_\n",
        "\n",
        "  # save results to dataframe\n",
        "  new_row = pd.DataFrame({'Model': ['Ridge'], 'Fold': [fold], 'Spearman': [s_cor[0]], 'Pearson': [p_cor[0]],\n",
        "                          'alpha': [alpha], 'max_iter': [max_iter]})\n",
        "  model_df = pd.concat([model_df, new_row],ignore_index = True)\n",
        "\n",
        "  # print results from fold\n",
        "  print(\"Fold\", fold, \"Spearman correlation:\", s_cor[0])\n",
        "\n",
        "  fold += 1\n",
        "\n",
        "# print results\n",
        "print(\"\\nBest correlation:\", best_corr, \"from Fold\", best_fold)\n",
        "\n",
        "# create feature importance dataframe\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Peak': X_train.columns,\n",
        "    'Weight': best_feat\n",
        "}).sort_values(by='Weight', ascending=False)\n",
        "\n",
        "# save feature importance dataframe\n",
        "filename = f\"ridge_features.csv\"\n",
        "feature_importance.to_csv(filename, index=False)\n",
        "\n",
        "model_df.to_csv('ridge.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePYbsSSGtnNl",
        "outputId": "83af739c-5fbe-42a8-ed7b-79cc4038948f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman correlation: 0.28303308818539497\n",
            "Fold 2 Spearman correlation: 0.49137218199787697\n",
            "Fold 3 Spearman correlation: 0.5010892722173464\n",
            "Fold 4 Spearman correlation: 0.41329041645839787\n",
            "Fold 5 Spearman correlation: 0.4248346657125048\n",
            "\n",
            "Best correlation: 0.5010892722173464 from Fold 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Elastic Net Model"
      ],
      "metadata": {
        "id": "oPtIrqbdts_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe to store results\n",
        "model_df = pd.DataFrame(columns=['Model', 'Fold', 'Spearman', 'Pearson', 'alpha', 'l1_ratio', 'max_iter'])\n",
        "\n",
        "# initialize the outer folds (5 folds, 80% train, 20% test)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# initialize variables to store best model correlation and features\n",
        "best_corr = 0\n",
        "best_fold = 0\n",
        "best_feat = None\n",
        "\n",
        "# loop through each of the outer five folds\n",
        "fold = 1\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "\n",
        "  # split train and test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # initialize Elastic Net model\n",
        "  en = linear_model.ElasticNet()\n",
        "\n",
        "  # specify parameters for optimization\n",
        "  parameters = {\n",
        "    'alpha': [0.1, 1, 10, 100],\n",
        "    'l1_ratio': [0.2, 0.5, 0.8],\n",
        "    'max_iter': [1000, 5000, 7500]\n",
        "  }\n",
        "\n",
        "  # identify optimal parameters\n",
        "  reg = GridSearchCV(\n",
        "      estimator = en,\n",
        "      param_grid = parameters,\n",
        "      #verbose=2\n",
        "    )\n",
        "\n",
        "  # fit model\n",
        "  reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # get best model parameters\n",
        "  reg_best = reg.best_estimator_\n",
        "\n",
        "  alpha = reg.best_params_['alpha']\n",
        "  l1_ratio = reg.best_params_['l1_ratio']\n",
        "  max_iter = reg.best_params_['max_iter']\n",
        "\n",
        "  # get predicted values for test data\n",
        "  y_pred = reg_best.predict(X_test_scaled)\n",
        "\n",
        "  # compute correlations\n",
        "  s_cor = stats.spearmanr(y_pred, y_test)\n",
        "  p_cor = stats.pearsonr(y_pred, y_test)\n",
        "\n",
        "  # save model correlation and features (if better than previous)\n",
        "  if s_cor[0] > best_corr:\n",
        "          best_corr = s_cor[0]\n",
        "          best_fold = fold\n",
        "          best_feat = reg_best.coef_\n",
        "\n",
        "  # save results to dataframe\n",
        "  new_row = pd.DataFrame({'Model': ['ElasticNet'], 'Fold': [fold], 'Spearman': [s_cor[0]], 'Pearson': [p_cor[0]], 'alpha': [alpha], 'l1_ratio': [l1_ratio], 'max_iter': [max_iter]})\n",
        "  model_df = pd.concat([model_df, new_row],ignore_index = True)\n",
        "\n",
        "  # print results from fold\n",
        "  print(\"Fold\", fold, \"Spearman correlation:\", s_cor[0])\n",
        "\n",
        "  fold += 1\n",
        "\n",
        "# print results\n",
        "print(\"\\nBest correlation:\", best_corr, \"from Fold\", best_fold)\n",
        "\n",
        "# create feature importance dataframe\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Peak': X_train.columns,\n",
        "    'Weight': best_feat\n",
        "}).sort_values(by='Weight', ascending=False)\n",
        "\n",
        "# save feature importance dataframe\n",
        "filename = f\"en_features.csv\"\n",
        "feature_importance.to_csv(filename, index=False)\n",
        "\n",
        "model_df.to_csv('en.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qjiKp_atuWx",
        "outputId": "16623edd-8a0f-4625-c3c0-73f08b100bb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman correlation: 0.3215366602002594\n",
            "Fold 2 Spearman correlation: 0.23544735644877304\n",
            "Fold 3 Spearman correlation: 0.38289814890148977\n",
            "Fold 4 Spearman correlation: 0.45226174370630895\n",
            "Fold 5 Spearman correlation: 0.43601057993349207\n",
            "\n",
            "Best correlation: 0.45226174370630895 from Fold 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest Model"
      ],
      "metadata": {
        "id": "Q0KY-YQ0t0z3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe to store results\n",
        "model_df = pd.DataFrame(columns=['Model', 'PSet', 'Fold', 'Spearman', 'Pearson', 'n_estimators', 'max_depth', 'min_samples_split', 'min_samples_leaf', 'max_features'])\n",
        "\n",
        "# initialize the outer folds (5 folds, 80% train, 20% test)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# initialize variables to store best model correlation and features\n",
        "best_corr = 0\n",
        "best_fold = 0\n",
        "best_feat = None\n",
        "\n",
        "# loop through each of the outer five folds\n",
        "fold = 1\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "\n",
        "  #print(\"Starting fold\", fold)\n",
        "\n",
        "  # split train and test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # initialize Random Forest model\n",
        "  rf = RandomForestRegressor()\n",
        "\n",
        "  # specify parameters for optimization\n",
        "  parameters = {\n",
        "    'n_estimators': [10, 50, 100, 150, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2, 5],\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "  }\n",
        "\n",
        "  # identify optimal parameters\n",
        "  reg = GridSearchCV(\n",
        "      estimator = rf,\n",
        "      param_grid = parameters,\n",
        "      #verbose=2\n",
        "    )\n",
        "\n",
        "  # fit model\n",
        "  reg.fit(X_train_scaled, y_train)\n",
        "\n",
        "  # get best model parameters\n",
        "  reg_best = reg.best_estimator_\n",
        "\n",
        "  n_estimators = reg.best_params_['n_estimators']\n",
        "  max_depth = reg.best_params_['max_depth']\n",
        "  min_samples_split = reg.best_params_['min_samples_split']\n",
        "  min_samples_leaf = reg.best_params_['min_samples_leaf']\n",
        "  max_features = reg.best_params_['max_features']\n",
        "\n",
        "  # get predicted values for test data\n",
        "  y_pred = reg_best.predict(X_test_scaled)\n",
        "\n",
        "  # compute correlations\n",
        "  s_cor = stats.spearmanr(y_pred, y_test)\n",
        "  p_cor = stats.pearsonr(y_pred, y_test)\n",
        "\n",
        "  # save model correlation and features (if better than previous)\n",
        "  if s_cor[0] > best_corr:\n",
        "          best_corr = s_cor[0]\n",
        "          best_fold = fold\n",
        "          best_feat = reg_best.feature_importances_\n",
        "\n",
        "  # save results to dataframe\n",
        "  new_row = pd.DataFrame({'Model': ['Random Forest'], 'Fold': [fold], 'Spearman': [s_cor[0]], 'Pearson': [p_cor[0]],\n",
        "                          'n_estimators': [n_estimators], 'max_depth': [max_depth], 'min_samples_split': [min_samples_split],\n",
        "                          'min_samples_leaf': [min_samples_leaf], 'max_features': [max_features]})\n",
        "  model_df = pd.concat([model_df, new_row],ignore_index = True)\n",
        "\n",
        "  # print results from fold\n",
        "  print(\"Fold\", fold, \"Spearman correlation:\", s_cor[0])\n",
        "\n",
        "  fold += 1\n",
        "\n",
        "# print results\n",
        "print(\"\\nBest correlation:\", best_corr, \"from Fold\", best_fold)\n",
        "\n",
        "# create feature importance dataframe\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Peak': X_train.columns,\n",
        "    'Weight': best_feat\n",
        "}).sort_values(by='Weight', ascending=False)\n",
        "\n",
        "# save feature importance dataframe\n",
        "filename = f\"rf_features.csv\"\n",
        "feature_importance.to_csv(filename, index=False)\n",
        "\n",
        "model_df.to_csv('rf.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t0m07PzNt25l",
        "outputId": "92e02949-b9a6-45e0-bef7-2090887ccb79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman correlation: 0.4353423139329869\n",
            "Fold 2 Spearman correlation: 0.4142188544963644\n",
            "Fold 3 Spearman correlation: 0.5018351969326591\n",
            "Fold 4 Spearman correlation: 0.5493393106262064\n",
            "Fold 5 Spearman correlation: 0.48578393357982674\n",
            "\n",
            "Best correlation: 0.5493393106262064 from Fold 4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost Model"
      ],
      "metadata": {
        "id": "WhW4LUOKwflm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create dataframe to store results\n",
        "model_df = pd.DataFrame(columns=['Model', 'PSet', 'Fold', 'Spearman', 'Pearson'])\n",
        "\n",
        "# initialize the outer folds (5 folds, 80% train, 20% test)\n",
        "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# initialize variables to store best model correlation and features\n",
        "best_corr = 0\n",
        "best_fold = 0\n",
        "best_feat = None\n",
        "\n",
        "# loop through each of the outer five folds\n",
        "fold = 1\n",
        "for train_index, test_index in outer_cv.split(X):\n",
        "\n",
        "  # split train and test\n",
        "  X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "  y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "  # Scale the features\n",
        "  scaler = StandardScaler()\n",
        "  X_train_scaled = scaler.fit_transform(X_train)\n",
        "  X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "  # initialize XGBoost model\n",
        "  reg = xgb.XGBRegressor(tree_method=\"hist\",\n",
        "                        early_stopping_rounds=2,\n",
        "                        eval_metric=\"rmse\", verbosity=0,\n",
        "                        objective='reg:squarederror',\n",
        "                        max_depth=5, subsample=0.8)\n",
        "\n",
        "  # fit model\n",
        "  reg.fit(X_train_scaled, y_train, eval_set = [(X_test_scaled, y_test)], verbose=0)\n",
        "\n",
        "  # get predicted values for test data\n",
        "  y_pred = reg.predict(X_test_scaled)\n",
        "\n",
        "  # compute correlations\n",
        "  s_cor = stats.spearmanr(y_pred, y_test)\n",
        "  p_cor = stats.pearsonr(y_pred, y_test)\n",
        "\n",
        "  # save model correlation and features (if better than previous)\n",
        "  if s_cor[0] > best_corr:\n",
        "          best_corr = s_cor[0]\n",
        "          best_fold = fold\n",
        "          best_feat = reg.feature_importances_\n",
        "\n",
        "  # save results to dataframe\n",
        "  new_row = pd.DataFrame({'Model': ['Random Forest'], 'Fold': [fold], 'Spearman': [s_cor[0]], 'Pearson': [p_cor[0]]})\n",
        "  model_df = pd.concat([model_df, new_row],ignore_index = True)\n",
        "\n",
        "  # print results from fold\n",
        "  print(\"Fold\", fold, \"Spearman correlation:\", s_cor[0])\n",
        "\n",
        "  fold += 1\n",
        "\n",
        "# print results\n",
        "print(\"\\nBest correlation:\", best_corr, \"from Fold\", best_fold)\n",
        "\n",
        "# create feature importance dataframe\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Peak': X_train.columns,\n",
        "    'Weight': best_feat\n",
        "}).sort_values(by='Weight', ascending=False)\n",
        "\n",
        "# save feature importance dataframe\n",
        "filename = f\"xg_features.csv\"\n",
        "feature_importance.to_csv(filename, index=False)\n",
        "\n",
        "model_df.to_csv('xg.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCCZvO5AwhVl",
        "outputId": "e4e987ef-f891-4d2e-a27d-825e9f541092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Spearman correlation: 0.3242947460344039\n",
            "Fold 2 Spearman correlation: 0.4268242632099374\n",
            "Fold 3 Spearman correlation: 0.47536812919016647\n",
            "Fold 4 Spearman correlation: 0.48367816860854423\n",
            "Fold 5 Spearman correlation: 0.5317665829657139\n",
            "\n",
            "Best correlation: 0.5317665829657139 from Fold 5\n"
          ]
        }
      ]
    }
  ]
}