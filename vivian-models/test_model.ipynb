{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'xai (Python 3.10.15)' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n xai ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "import scanpy as sc\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = \"/home/vivian.chu/vivian-sandbox/other/xAI-cancer-competition/.data\"\n",
    "out_dir = \"/home/vivian.chu/vivian-sandbox/other/xAI-cancer-competition/vivian-models\"\n",
    "\n",
    "# Load data\n",
    "train_data = pd.read_csv(f\"{data_dir}/train.csv\")\n",
    "train_targets = pd.read_csv(f\"{data_dir}/train_targets.csv\")\n",
    "test_data = pd.read_csv(f\"{data_dir}/test.csv\")\n",
    "\n",
    "# Preprocess data\n",
    "train_data.rename(columns={'Unnamed: 0': 'sample'}, inplace=True)\n",
    "train_data['sample'] = train_data['sample'].astype(str)\n",
    "train_targets['sample'] = train_targets['sample'].astype(str)\n",
    "test_data['sampleId'] = test_data['sampleId'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (742, 19921)\n",
      "Test: (304, 19921)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", train_data.shape)\n",
    "print(\"Test:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge train data and targets\n",
    "train = train_data.merge(train_targets, on=\"sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Scanpy for highly variable gene selection\n",
    "adata = sc.AnnData(X=train.iloc[:, 1:-2].values, obs=train[[\"sample\", \"AAC\", \"tissue\"]])\n",
    "sc.pp.normalize_total(adata)\n",
    "sc.pp.log1p(adata)\n",
    "sc.pp.highly_variable_genes(adata, n_top_genes=2000)\n",
    "selected_genes = adata.var[adata.var['highly_variable']].index\n",
    "train_X = adata[:, selected_genes].X\n",
    "train_y = adata.obs[\"AAC\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_data[selected_genes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train into train/validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset and DataLoader\n",
    "class ExpressionDataset(Dataset):\n",
    "    def __init__(self, X, y=None):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.X[idx], self.y[idx]\n",
    "        return self.X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = ExpressionDataset(X_train, y_train)\n",
    "val_dataset = ExpressionDataset(X_val, y_val)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class DrugResponseModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(DrugResponseModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "input_size = X_train.shape[1]\n",
    "model = DrugResponseModel(input_size)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train_model(model, train_loader, val_loader, epochs=50):\n",
    "    best_spearman = -1\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(X_batch).squeeze()\n",
    "            loss = criterion(preds, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_preds, val_true = [], []\n",
    "        with torch.no_grad():\n",
    "            for X_batch, y_batch in val_loader:\n",
    "                preds = model(X_batch).squeeze()\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_true.extend(y_batch.cpu().numpy())\n",
    "        \n",
    "        spearman = spearmanr(val_preds, val_true)[0]\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Spearman: {spearman:.4f}\")\n",
    "        if spearman > best_spearman:\n",
    "            best_spearman = spearman\n",
    "            torch.save(model.state_dict(), f\"{out_dir}/best_model.pth\")\n",
    "    return best_spearman\n",
    "\n",
    "# Train the model\n",
    "best_spearman = train_model(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "model.load_state_dict(torch.load(f\"{out_dir}/best_model.pth\"))\n",
    "\n",
    "# Predict on test data\n",
    "test_dataset = ExpressionDataset(test_X)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "model.eval()\n",
    "test_preds = []\n",
    "with torch.no_grad():\n",
    "    for X_batch in test_loader:\n",
    "        preds = model(X_batch).squeeze()\n",
    "        test_preds.extend(preds.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions\n",
    "test_preds_df = pd.DataFrame({\"sampleId\": test_data[\"sampleId\"], \"AAC\": test_preds})\n",
    "test_preds_df.to_csv(f\"{out_dir}/test_predictions.csv\", index=False)\n",
    "\n",
    "print(\"Test predictions saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
