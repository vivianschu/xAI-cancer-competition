{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1p5wamGuy0V8BmMWQ7CfKqlo6uXRNGmbO","authorship_tag":"ABX9TyOelEbQLbxXD0Qw9iuJBuly"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"YCjAUn-Ogwtv","executionInfo":{"status":"ok","timestamp":1733530240295,"user_tz":300,"elapsed":10007,"user":{"displayName":"Julia Nguyen","userId":"02226039291033821968"}}},"outputs":[],"source":["# load libraries\n","import pandas as pd\n","import numpy as np\n","from sklearn import linear_model\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import StandardScaler\n","import xgboost as xgb\n","from scipy import stats\n","\n","import warnings\n","\n","# suppress all warnings\n","warnings.filterwarnings('ignore')\n","\n","# set seed\n","np.random.seed(42)"]},{"cell_type":"code","source":["# specify file paths\n","train_df1 = \"train_subset.csv\"\n","train_targets1 = \"train_targets.csv\"\n","train_df2 = \"train_subset_375.csv\"\n","train_targets2 = \"targets_375.csv\"\n","test_df = \"test.csv\"\n","\n","# read in files\n","X_train1 = pd.read_csv(train_df1)\n","y_train1 = pd.read_csv(train_targets1)['AAC']\n","X_train2 = pd.read_csv(train_df2)\n","y_train2 = pd.read_csv(train_targets2)['AAC']\n","X_test1 = pd.read_csv(test_df)\n","X_test2 = pd.read_csv(test_df)\n","\n","# filter to keep only relevant genes\n","X_test1 = X_test1[X_train1.columns]\n","X_test2 = X_test2[X_train2.columns]\n","\n","print(X_train1.shape)\n","print(y_train1.shape)\n","print(X_train2.shape)\n","print(y_train2.shape)\n","print(X_test1.shape)\n","print(X_test2.shape)"],"metadata":{"id":"FJUsIM2FlVxT","executionInfo":{"status":"ok","timestamp":1733530455045,"user_tz":300,"elapsed":7813,"user":{"displayName":"Julia Nguyen","userId":"02226039291033821968"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a0369e2a-0a66-4c3c-e189-137db8978163"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["(742, 457)\n","(742,)\n","(662, 510)\n","(662,)\n","(304, 457)\n","(304, 510)\n"]}]},{"cell_type":"markdown","source":["Submission Title: EN-ensemble-weighted 100/10: Dec6\n","\n","Ensemble top two Elastic Nets\n","\n","Submission Score:"],"metadata":{"id":"KsQyvFSDd8v2"}},{"cell_type":"code","source":["# initialize models\n","enALL = linear_model.ElasticNet(alpha = 1,\n","                              l1_ratio = 1,\n","                              max_iter = 1000)\n","en375 = linear_model.ElasticNet(alpha = 10,\n","                              l1_ratio = 0.2,\n","                              max_iter = 1000)\n","\n","# fit model\n","enALL.fit(X_train1, y_train1)\n","en375.fit(X_train2, y_train2)\n","\n","# get predicted values for test data\n","pred1 = enALL.predict(X_test1)\n","pred2 = en375.predict(X_test2)\n","\n","# average predictions\n","y_pred = (pred1 * 0.1 + pred2) / 2\n","\n","# save predictions\n","sample_ids = [f\"TS{i}\" for i in range(1, 305)]\n","predictions = pd.DataFrame({\n","    'sampleId': sample_ids,\n","    'AAC': y_pred})\n","predictions.to_csv(\"en-ensemble-pred.csv\", index = False)"],"metadata":{"id":"IXDlwIOdd6Tq","executionInfo":{"status":"ok","timestamp":1733530483127,"user_tz":300,"elapsed":143,"user":{"displayName":"Julia Nguyen","userId":"02226039291033821968"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["Submission Title: EN-ensemble-weighted 100/30: Dec6\n","\n","Ensemble top two Elastic Nets\n","\n","Submission Score: 0.45538"],"metadata":{"id":"0fUweMvcjDGP"}},{"cell_type":"code","source":["# initialize models\n","enALL = linear_model.ElasticNet(alpha = 1,\n","                              l1_ratio = 1,\n","                              max_iter = 1000)\n","en375 = linear_model.ElasticNet(alpha = 10,\n","                              l1_ratio = 0.2,\n","                              max_iter = 1000)\n","\n","# fit model\n","enALL.fit(X_train1, y_train1)\n","en375.fit(X_train2, y_train2)\n","\n","# get predicted values for test data\n","pred1 = enALL.predict(X_test1)\n","pred2 = en375.predict(X_test2)\n","\n","# average predictions\n","y_pred = (pred1 * 0.3 + pred2) / 2\n","\n","# save predictions\n","sample_ids = [f\"TS{i}\" for i in range(1, 305)]\n","predictions = pd.DataFrame({\n","    'sampleId': sample_ids,\n","    'AAC': y_pred})\n","predictions.to_csv(\"en-ensemble-pred.csv\", index = False)"],"metadata":{"id":"HPVzuydki7jI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Submission Title: EN-ensemble-weighted 80/30: Dec6\n","\n","Ensemble top two Elastic Nets\n","\n","Submission Score: 0.45491"],"metadata":{"id":"-c5MpS6ZUbff"}},{"cell_type":"code","source":["# initialize models\n","enALL = linear_model.ElasticNet(alpha = 1,\n","                              l1_ratio = 1,\n","                              max_iter = 1000)\n","en375 = linear_model.ElasticNet(alpha = 10,\n","                              l1_ratio = 0.2,\n","                              max_iter = 1000)\n","\n","# fit model\n","enALL.fit(X_train1, y_train1)\n","en375.fit(X_train2, y_train2)\n","\n","# get predicted values for test data\n","pred1 = enALL.predict(X_test1)\n","pred2 = en375.predict(X_test2)\n","\n","# average predictions\n","y_pred = (pred1 * 0.3 + pred2 * 0.8) / 2\n","\n","# save predictions\n","sample_ids = [f\"TS{i}\" for i in range(1, 305)]\n","predictions = pd.DataFrame({\n","    'sampleId': sample_ids,\n","    'AAC': y_pred})\n","predictions.to_csv(\"en-ensemble-pred.csv\", index = False)"],"metadata":{"id":"uY5BK-FcUeh5"},"execution_count":null,"outputs":[]}]}